{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tokens import FullTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import statistics\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(input_string: str) -> list:\n",
    "    res = input_string.strip('][')\n",
    "    res = res.replace('\"', '')\n",
    "    res = res.split(', ')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(row):\n",
    "    for label in row[\"reiss\"]:\n",
    "        if label == 'na':\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "    \n",
    "def preprocess(file, bert_layer, only_a_few=False):\n",
    "    file = file[file['action'] != 'no']\n",
    "    file = file[file['motivation'] != 'none']\n",
    "    file = file[file['maslow'] != '[]']\n",
    "    file = file[file['reiss'] != '[]']\n",
    "    file = file[file['reiss'] != '[\"na\"]']\n",
    "    file[\"maslow\"] = file[\"maslow\"].apply(string_to_list)\n",
    "    file[\"reiss\"] = file[\"reiss\"].apply(string_to_list)\n",
    "    file = file[file.apply(my_filter, axis=1)]\n",
    "    file.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "    mlb_m = MultiLabelBinarizer()\n",
    "    labels_m = mlb_m.fit_transform(file[\"maslow\"])\n",
    "\n",
    "    mlb_r = MultiLabelBinarizer()\n",
    "    labels_r = mlb_r.fit_transform(file[\"reiss\"])\n",
    "\n",
    "    labels = np.concatenate((labels_m, labels_r), axis=1)\n",
    "\n",
    "    data = bert_encode(file['sentence'].values, tokenizer, only_a_few=only_a_few)\n",
    "\n",
    "    if only_a_few:\n",
    "        o_labels = labels[0:32, :]\n",
    "        return data, o_labels\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_motivation = pd.read_csv(os.path.join(\"data/dev/motivation\", \"allcharlinepairs_noids.csv\"))\n",
    "testing_file_motivation = pd.read_csv(os.path.join(\"data/test/motivation\", \"allcharlinepairs_noids.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def bert_encode(texts, tokenizer, max_len=128, only_a_few=False):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "\n",
    "    j = 0\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        \n",
    "\n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "\n",
    "        j += 1\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=128):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(5, activation='sigmoid')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_labels = preprocess(training_file_motivation, bert_layer)\n",
    "test_input, test_labels = preprocess(testing_file_motivation, bert_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 128, 768)]                'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['keras_layer[0][1]']            \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5)            165         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,702\n",
      "Trainable params: 109,533,701\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "256/718 [=========>....................] - ETA: 12:17:17 - loss: 2.0168 - accuracy: 0.3302"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels, \n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5)\n",
      "(32, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4074074074074074, 0.2619047619047619, 0.3188405797101449, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = model.predict(test_input)\n",
    "test_output = np.rint(test_output)\n",
    "\n",
    "print(test_output.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "precision_recall_fscore_support(test_labels, test_output, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        #self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_x = tf.Variable(tf.ones(shape = [sequence_length]), dtype=tf.float32)\n",
    "        #self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.input_y = tf.Variable(tf.ones(shape = [num_classes], dtype=tf.float32))\n",
    "        #self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "        self.dropout_keep_prob = tf.Variable(tf.ones(1), dtype = tf.float32)\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        print(args)\n",
    "        self.args = args\n",
    "        \n",
    "        V = args['embed_num']\n",
    "        D = args['embed_dim']\n",
    "        C = args['class_num']\n",
    "        Ci = 1\n",
    "        Co = args['kernel_num']\n",
    "        Ks = args['kernel_sizes']\n",
    "\n",
    "        # V -> number of embeddings -> 128, sentence_size\n",
    "        # D -> embedding dimension -> 768, bert output size\n",
    "        # W\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(args['dropout'])\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "\n",
    "        if self.args['static']:\n",
    "            self.embed.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "    \n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "bert_preprocessing_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(bert_preprocessing_link)\n",
    "bert_model = hub.KerasLayer(bert_model_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(bert_layer, max_len=128):\n",
    "  #text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  #preprocessing_layer = hub.KerasLayer(bert_preprocessing_link, name='preprocessing')\n",
    "  #encoder_inputs = preprocessing_layer(text_input)\n",
    "  #encoder = hub.KerasLayer(bert_model_link, trainable=True, name='BERT_encoder')\n",
    "  #outputs = encoder(encoder_inputs)\n",
    "  #return tf.keras.Model(text_input, outputs)\n",
    "\n",
    "  input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "  input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "  segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "  model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=sequence_output)\n",
    "  model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "bert_raw_model = build_model2(bert_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_2\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(32,), dtype=string, numpy=\narray([b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b'I let the curry sit before tasting.',\n       b'I let the curry sit before tasting.',\n       b'I let the curry sit before tasting.',\n       b'When it was time to taste, I was disgusted.',\n       b'When it was time to taste, I was disgusted.',\n       b'When it was time to taste, I was disgusted.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'Jervis has been single for a long time.',\n       b'Jervis has been single for a long time.',\n       b'Jervis has been single for a long time.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'They begin to date.', b'They begin to date.'], dtype=object)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9m/clqv80fs2893t0s91x7ghvk80000gn/T/ipykernel_88138/144175930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmall_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_file_motivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_raw_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\u001b[0m\u001b[1;32m    200\u001b[0m                      \u001b[0;34mf' but it received {len(inputs)} input tensors. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                      f'Inputs received: {inputs}')\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"model_2\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(32,), dtype=string, numpy=\narray([b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b'I began making fish curry for my boyfriend and I.',\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b\"I decided not to read a recipe since I've made so many in my life.\",\n       b'I let the curry sit before tasting.',\n       b'I let the curry sit before tasting.',\n       b'I let the curry sit before tasting.',\n       b'When it was time to taste, I was disgusted.',\n       b'When it was time to taste, I was disgusted.',\n       b'When it was time to taste, I was disgusted.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'I accidentally used a whole garlic instead of a whole onion.',\n       b'Jervis has been single for a long time.',\n       b'Jervis has been single for a long time.',\n       b'Jervis has been single for a long time.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'He wants to have a girlfriend.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'One day he meets a nice girl at the grocery store.',\n       b'They begin to date.', b'They begin to date.'], dtype=object)>]"
     ]
    }
   ],
   "source": [
    "small_test = training_file_motivation[0:32][\"sentence\"].values\n",
    "out = bert_raw_model(small_test)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 768)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(out['sequence_output'].shape)\n",
    "print(type(out[\"sequence_output\"]))\n",
    "# Batch Size, Sentence Size, Embedding Size\n",
    "# 32\n",
    "# 128\n",
    "# 768\n",
    "npout = out[\"sequence_output\"].numpy()\n",
    "torchout = torch.from_numpy(npout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embed_num': 128, 'embed_dim': 768, 'class_num': 5, 'kernel_num': 100, 'kernel_sizes': [3, 4, 5], 'dropout': 0.5, 'static': False}\n"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "args['embed_num'] = 128\n",
    "args['embed_dim'] = 768\n",
    "args['class_num'] = 5\n",
    "args['kernel_num'] = 100\n",
    "args['kernel_sizes'] = [3, 4, 5]\n",
    "args['dropout'] = 0.5\n",
    "args['static'] = False\n",
    "cnn = CNN_Text(\n",
    "    args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 768])\n",
      "tensor([[ 9.6613e-02, -3.8865e-02, -2.8047e-01,  ..., -4.9758e-01,\n",
      "          4.7888e-01,  3.5955e-01],\n",
      "        [ 5.8334e-01, -2.1532e-01, -4.6476e-01,  ..., -1.9645e-01,\n",
      "          8.5647e-01,  7.0585e-02],\n",
      "        [-2.5741e-01,  3.2241e-01, -1.0095e+00,  ..., -1.0464e-01,\n",
      "          4.4049e-01, -9.8860e-01],\n",
      "        ...,\n",
      "        [ 5.2097e-01, -5.9698e-02,  2.5945e-01,  ...,  8.6826e-04,\n",
      "          6.0448e-02, -2.0960e-01],\n",
      "        [ 2.1364e-01, -2.0435e-01,  6.2357e-02,  ...,  2.0564e-01,\n",
      "          2.1234e-01, -4.5383e-01],\n",
      "        [ 3.6563e-01,  9.4640e-02,  3.0396e-01,  ..., -1.6612e-02,\n",
      "         -5.0270e-02, -2.3940e-01]])\n",
      "torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "print(torchout.shape)\n",
    "print(torchout[0])\n",
    "model_out = cnn.forward(torchout)\n",
    "\n",
    "print(model_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:870: UserWarning: unknown class(es) ['gong'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb1 = MultiLabelBinarizer()\n",
    "mlb1.fit([[\"maslow\"], [\"reiss\"], [\"plutchik\"]])\n",
    "out = mlb1.transform([\n",
    "    [\"maslow\"], [\"reiss\", \"gong\"]\n",
    "])\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>action</th>\n",
       "      <th>motivation</th>\n",
       "      <th>maslow</th>\n",
       "      <th>reiss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>eat some food</td>\n",
       "      <td>[physiological]</td>\n",
       "      <td>[\"food\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>to be nice</td>\n",
       "      <td>[love, physiological]</td>\n",
       "      <td>[\"family\", \"romance\", \"food\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>to satisfy a craving.</td>\n",
       "      <td>[physiological]</td>\n",
       "      <td>[\"food\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>Boyfriend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>no</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>to help out</td>\n",
       "      <td>[spiritual growth]</td>\n",
       "      <td>[\"indep\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>confidence</td>\n",
       "      <td>[physiological]</td>\n",
       "      <td>[\"food\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>to prove knowledge</td>\n",
       "      <td>[spiritual growth]</td>\n",
       "      <td>[\"indep\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>Boyfriend</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>no</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>3</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I let the curry sit before tasting.</td>\n",
       "      <td>yes</td>\n",
       "      <td>cook good food</td>\n",
       "      <td>[esteem, love]</td>\n",
       "      <td>[\"competition\", \"approval\", \"romance\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>3</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I let the curry sit before tasting.</td>\n",
       "      <td>yes</td>\n",
       "      <td>to trust myself</td>\n",
       "      <td>[spiritual growth, esteem]</td>\n",
       "      <td>[\"indep\", \"competition\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                storyid  linenum        char  \\\n",
       "0  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "1  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "2  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "3  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1   Boyfriend   \n",
       "4  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "5  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "6  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "7  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2   Boyfriend   \n",
       "8  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        3  I (myself)   \n",
       "9  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        3  I (myself)   \n",
       "\n",
       "                                             context  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  I began making fish curry for my boyfriend and I.   \n",
       "5  I began making fish curry for my boyfriend and I.   \n",
       "6  I began making fish curry for my boyfriend and I.   \n",
       "7  I began making fish curry for my boyfriend and I.   \n",
       "8  I began making fish curry for my boyfriend and...   \n",
       "9  I began making fish curry for my boyfriend and...   \n",
       "\n",
       "                                            sentence action  \\\n",
       "0  I began making fish curry for my boyfriend and I.    yes   \n",
       "1  I began making fish curry for my boyfriend and I.    yes   \n",
       "2  I began making fish curry for my boyfriend and I.    yes   \n",
       "3  I began making fish curry for my boyfriend and I.     no   \n",
       "4  I decided not to read a recipe since I've made...    yes   \n",
       "5  I decided not to read a recipe since I've made...    yes   \n",
       "6  I decided not to read a recipe since I've made...    yes   \n",
       "7  I decided not to read a recipe since I've made...     no   \n",
       "8                I let the curry sit before tasting.    yes   \n",
       "9                I let the curry sit before tasting.    yes   \n",
       "\n",
       "              motivation                      maslow  \\\n",
       "0          eat some food             [physiological]   \n",
       "1             to be nice       [love, physiological]   \n",
       "2  to satisfy a craving.             [physiological]   \n",
       "3               [\"none\"]                      [none]   \n",
       "4            to help out          [spiritual growth]   \n",
       "5             confidence             [physiological]   \n",
       "6     to prove knowledge          [spiritual growth]   \n",
       "7               [\"none\"]                      [none]   \n",
       "8         cook good food              [esteem, love]   \n",
       "9        to trust myself  [spiritual growth, esteem]   \n",
       "\n",
       "                                    reiss  \n",
       "0                                [\"food\"]  \n",
       "1           [\"family\", \"romance\", \"food\"]  \n",
       "2                                [\"food\"]  \n",
       "3                                [\"none\"]  \n",
       "4                               [\"indep\"]  \n",
       "5                                [\"food\"]  \n",
       "6                               [\"indep\"]  \n",
       "7                                [\"none\"]  \n",
       "8  [\"competition\", \"approval\", \"romance\"]  \n",
       "9                [\"indep\", \"competition\"]  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_motivation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_maslow(df):\n",
    "    all_maslow = df.values.sum()\n",
    "    most_freq = mode(all_maslow)\n",
    "    if most_freq == '':\n",
    "        most_freq = 'none'\n",
    "    return [most_freq]\n",
    "\n",
    "def combine_reiss(df):\n",
    "    all_reiss = df.values.sum()\n",
    "    most_freq = mode(all_reiss)\n",
    "    if most_freq == 'na' or most_freq == '':\n",
    "        most_freq = 'none'\n",
    "    return [most_freq]\n",
    "\n",
    "def combine_sentence(df):\n",
    "    full_sentence = []\n",
    "    full_sentence.append([df['char']])\n",
    "    full_sentence.append([df['sentence']])\n",
    "    \n",
    "    if not pd.isnull(df['context']):\n",
    "        split_context = df['context'].split(\"|\")\n",
    "        i = len(split_context) - 1\n",
    "        while i >= 0:\n",
    "            full_sentence.append([split_context[i]])\n",
    "            i -= 1\n",
    "\n",
    "    return full_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(training_file_motivation['context'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_motivation[\"maslow\"] = training_file_motivation[\"maslow\"].apply(string_to_list)\n",
    "training_file_motivation[\"reiss\"] = training_file_motivation[\"reiss\"].apply(string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>maslow</th>\n",
       "      <th>reiss</th>\n",
       "      <th>full_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[[My daughter], [Nana came into the room with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>1</td>\n",
       "      <td>Nana</td>\n",
       "      <td>[stability]</td>\n",
       "      <td>[order]</td>\n",
       "      <td>[[Nana], [Nana came into the room with a puzzl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>2</td>\n",
       "      <td>My daughter</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[[My daughter], [She held up an orange sock an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>2</td>\n",
       "      <td>Nana</td>\n",
       "      <td>[stability]</td>\n",
       "      <td>[order]</td>\n",
       "      <td>[[Nana], [She held up an orange sock and a blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>3</td>\n",
       "      <td>My daughter</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[[My daughter], [My daughter jumped up and gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>3</td>\n",
       "      <td>Nana</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[[Nana], [My daughter jumped up and grabbed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>4</td>\n",
       "      <td>My daughter</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[family]</td>\n",
       "      <td>[[My daughter], [She took off running down the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>4</td>\n",
       "      <td>Nana</td>\n",
       "      <td>[esteem]</td>\n",
       "      <td>[status]</td>\n",
       "      <td>[[Nana], [She took off running down the hall w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter</td>\n",
       "      <td>[spiritual growth]</td>\n",
       "      <td>[serenity]</td>\n",
       "      <td>[[My daughter], [Nana chased her down, caught ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0008c800-82b6-43b3-8b53-5475ed1dac9b</td>\n",
       "      <td>5</td>\n",
       "      <td>Nana</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[family]</td>\n",
       "      <td>[[Nana], [Nana chased her down, caught her, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                storyid  linenum         char  \\\n",
       "0  0008c800-82b6-43b3-8b53-5475ed1dac9b        1  My daughter   \n",
       "1  0008c800-82b6-43b3-8b53-5475ed1dac9b        1         Nana   \n",
       "2  0008c800-82b6-43b3-8b53-5475ed1dac9b        2  My daughter   \n",
       "3  0008c800-82b6-43b3-8b53-5475ed1dac9b        2         Nana   \n",
       "4  0008c800-82b6-43b3-8b53-5475ed1dac9b        3  My daughter   \n",
       "5  0008c800-82b6-43b3-8b53-5475ed1dac9b        3         Nana   \n",
       "6  0008c800-82b6-43b3-8b53-5475ed1dac9b        4  My daughter   \n",
       "7  0008c800-82b6-43b3-8b53-5475ed1dac9b        4         Nana   \n",
       "8  0008c800-82b6-43b3-8b53-5475ed1dac9b        5  My daughter   \n",
       "9  0008c800-82b6-43b3-8b53-5475ed1dac9b        5         Nana   \n",
       "\n",
       "               maslow       reiss  \\\n",
       "0              [none]      [none]   \n",
       "1         [stability]     [order]   \n",
       "2              [none]      [none]   \n",
       "3         [stability]     [order]   \n",
       "4              [none]      [none]   \n",
       "5              [none]      [none]   \n",
       "6              [love]    [family]   \n",
       "7            [esteem]    [status]   \n",
       "8  [spiritual growth]  [serenity]   \n",
       "9              [love]    [family]   \n",
       "\n",
       "                                       full_sentence  \n",
       "0  [[My daughter], [Nana came into the room with ...  \n",
       "1  [[Nana], [Nana came into the room with a puzzl...  \n",
       "2  [[My daughter], [She held up an orange sock an...  \n",
       "3  [[Nana], [She held up an orange sock and a blu...  \n",
       "4  [[My daughter], [My daughter jumped up and gra...  \n",
       "5  [[Nana], [My daughter jumped up and grabbed th...  \n",
       "6  [[My daughter], [She took off running down the...  \n",
       "7  [[Nana], [She took off running down the hall w...  \n",
       "8  [[My daughter], [Nana chased her down, caught ...  \n",
       "9  [[Nana], [Nana chased her down, caught her, an...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_motivation['full_sentence'] = training_file_motivation.apply(combine_sentence, axis=1)\n",
    "groups_motivation = training_file_motivation.groupby(['storyid', 'linenum', 'char']).aggregate({\n",
    "    'maslow': lambda x: combine_maslow(x),\n",
    "    'reiss':  lambda x: combine_reiss(x),\n",
    "    'full_sentence': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "groups_motivation.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = []\n",
    "input_seq = [\"a\"] + [\"b\"]\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 1]\n",
      "  [0 0 1]]\n",
      "\n",
      " [[0 1 0]\n",
      "  [1 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [[1, 2, 3], [2, 3, 4]],\n",
    "    [[1, 5, 3], [5, 3, 4]]\n",
    "])\n",
    "\n",
    "def predict_one_hot(x):\n",
    "    d = x.reshape(-1, x.shape[-1])\n",
    "    d2 = np.zeros_like(d)\n",
    "    d2[np.arange(len(d2)), d.argmax(1)] = 1\n",
    "    d2 = d2.reshape(x.shape)\n",
    "    return d2\n",
    "\n",
    "x = np.apply_along_axis(predict_one_hot, axis=2, arr=x)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
